{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tagowanie części mowy - Pierwsze kroki: Praca z plikami tekstowymi, tworzenie słownika i obsługa nieznanych słów"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "W tym notebooku stworzysz słownik z oznaczonego zbioru danych i nauczysz się radzić sobie ze słowami, które nie są obecne w tym słowniku podczas pracy z innymi źródłami tekstu. Poza tym nauczysz się również jak:\n",
    " \n",
    "- czytać pliki tekstowe\n",
    "- pracować z defaultdict\n",
    "- pracować z ciągami znaków (stringami)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Odczyt danych tekstowych"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Oznaczony zbiór danych pobrany z Wall Street Journal znajduje się w pliku `WSJ_02-21.pos`. \n",
    "\n",
    "Aby odczytać ten plik, możesz użyć menedżera kontekstowego Pythona, używając słowa kluczowego `with` i określając nazwę pliku, który chcesz przeczytać. Aby faktycznie zapisać zawartość pliku do pamięci, należy użyć metody `readlines()` i zapisać jego wartość zwrotną w zmiennej. \n",
    "\n",
    "Menadżery kontekstowe Pythona są świetne, ponieważ nie trzeba wyraźnie zamykać połączenia z plikiem, robi się to pod spodem:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Odczyt danych z pliku 'WSJ_02-21.pos' i zapis do zmiennej 'lines'\n",
    "with open(\"WSJ_02-21.pos\", 'r') as f:\n",
    "    lines = f.readlines()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aby sprawdzić zawartość zbioru danych wypiszmy pierwsze 5 wierszy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t\tWord \tTag\n",
      "\n",
      "line number 1: In\tIN\n",
      "\n",
      "line number 2: an\tDT\n",
      "\n",
      "line number 3: Oct.\tNNP\n",
      "\n",
      "line number 4: 19\tCD\n",
      "\n",
      "line number 5: review\tNN\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print columns for reference\n",
    "print(\"\\t\\tWord\", \"\\tTag\\n\")\n",
    "\n",
    "# Print first five lines of the dataset\n",
    "for i in range(5):\n",
    "    print(f'line number {i+1}: {lines[i]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Każdy wiersz w zbiorze danych ma słowo, po którym następuje odpowiedni tag. Ponieważ jednak wydruk został wykonany przy użyciu sformatowanego łańcucha, można wnioskować, że **word** i **tag** są oddzielone tabulatorem (lub kilkoma spacjami) i na końcu każdego wiersza znajduje się nowy wiersz (zauważ, że między każdym wierszem jest spacja). \n",
    "\n",
    "Jeśli chcesz zrozumieć znaczenie tych tagów, możesz zajrzeć [tutaj](https://www.ling.upenn.edu/courses/Fall_2003/ling001/penn_treebank_pos.html).\n",
    "\n",
    "Aby lepiej zrozumieć strukturę informacji w zbiorze danych, zaleca się wydrukowanie jej niesformatowanej wersji:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'In\\tIN\\n'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print first line (unformatted)\n",
    "lines[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rzeczywiście pomiędzy słowem i tagiem znajduje się tabulator a na końcu każdego wiersza jest nowa linia.\n",
    "\n",
    "### Tworzenie słownika\n",
    "\n",
    "Teraz, gdy rozumiesz, jak zbudowany jest zbiór danych, stworzysz z niego słownik. Słownik składa się z każdego słowa, które pojawiło się w zbiorze danych co najmniej 2 razy. \n",
    "W tym celu wykonaj poniższe kroki:\n",
    "- Pobierz tylko słowa ze zbioru danych\n",
    "- Użyj defaultdict, aby zliczyć ilość razy, kiedy pojawia się każde słowo.\n",
    "- Przefiltruj dict tak, aby zawierało tylko te słowa, które pojawiły się co najmniej 2 razy\n",
    "- Stwórzcie listę z przefiltrowanego dict\n",
    "- Posortuj listę\n",
    "\n",
    "W kroku 1 można wykorzystać fakt, że każde słowo i znacznik są oddzielone tabulatorem i że słowa zawsze znajdują się na pierwszym miejscu. Korzystając ze comprehension list, można w ten sposób stworzyć listę słów:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# z każdej linii ze zbioru danych wyciągamy tylko słowo\n",
    "words = [line.split('\\t')[0] for line in lines]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Krok 2 można wykonać z łatwością, używając `defaultdict`. W przypadku, gdy nie jesteś zaznajomiony z defaultdicts, są to specjalne rodzaje słowników, które **zwracają wartość \"zero\" danego typu, jeśli spróbujesz uzyskać dostęp do klucza, który nie istnieje**. Ponieważ zależy ci na częstotliwości występowania słów, powinieneś zdefiniować defaultdict z typem `int`. \n",
    "\n",
    "Teraz nie musisz się martwić o przypadek, gdy słowa nie ma w słowniku, ponieważ uzyskanie wartości dla tego klucza po prostu zwróci zero. Czy to nie jest fajne?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definiujemy defaultdict z typem 'int'\n",
    "freq = defaultdict(int)\n",
    "\n",
    "# zliczamy pojawienie się każdego słowa w zbiorze danych\n",
    "for word in words:\n",
    "    freq[word] += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filtrowanie słownika `freq` może być wykonane przy użyciu list comprehension (czyż nie są one przydatne?). Należy odfiltrować słowa, które pojawiły się tylko raz, a także słowa, które są tylko znakiem nowej linii:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tworzymy słownika ze słownika 'freq'\n",
    "vocab = [k for k, v in freq.items() if (v > 1 and k != '\\n')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "W końcu, metoda \"sort\" zajmie się ostatnim etapem. Zauważ, że zmienia ona listę bezpośrednio, więc nie ma potrzeby ponownego przypisywania zmiennej `vocab`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early\n",
      "Earnings\n",
      "Earth\n",
      "Earthquake\n",
      "East\n"
     ]
    }
   ],
   "source": [
    "# Sortujemy słownik\n",
    "vocab.sort()\n",
    "\n",
    "# Wypiszmy kilka przykładowych wartości ze słownika\n",
    "for i in range(4000, 4005):\n",
    "    print(vocab[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Teraz udało Ci się stworzyć słownik ze zbioru danych. **Wspaniała praca!** Słownik jest dość obszerny, więc nie będziemy go wypisywać w całości, ale możesz to zrobić, tworząc komórkę i uruchamiając coś w rodzaju `print(vocab)`. \n",
    "\n",
    "W tym momencie zazwyczaj będziesz zapisywał słownik do pliku do wykorzystania w przyszłości, ale to jest poza zakresem tego notebooka Jeśli jesteś ciekawy, to jest to bardzo podobne do tego, jak odczytuje ten plik na początku tego notebooka.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Procesowanie nowych źródeł tekstu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Radzenie sobie z nieznanymi słowami (spoza słownika)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Teraz, gdy masz już słownik, będziesz go używał podczas przetwarzania nowych źródeł tekstu. **Nowy tekst będzie zawierał słowa, które nie występują w obecnym słowniku**. Aby temu zaradzić, możesz po prostu sklasyfikować każde nowe słowo jako nieznane, ale możesz zrobić to lepiej, tworząc funkcję, która próbuje sklasyfikować typ każdego nieznanego słowa i przypisać mu odpowiedni `nieznany token`. \n",
    "\n",
    "Funkcja ta wykona następujące czynności sprawdzające i zwróci odpowiedni token:\n",
    "\n",
    "   - Sprawdza, czy nieznane słowo zawiera dowolny znak będący cyfrą \n",
    "       - `--unk_digit--`\n",
    "   - Sprawdź, czy nieznane słowo zawiera jakiś znak interpunkcyjny \n",
    "       - `--unk_punct--`\n",
    "   - Sprawdź, czy nieznane słowo zawiera jakieś duże litery. \n",
    "       - `--unk_upper--`\n",
    "   - Sprawdź, czy nieznany wyraz kończy się przyrostkiem, który może wskazywać na to, że jest odpowiednio rzeczownikiem, czasownikiem, przymiotnikiem lub przysłówkiem. \n",
    "        - return `--unk_noun--`, `--unk_verb--`, `--unk_adj--`, `--unk_adv--` \n",
    "\n",
    "Jeśli słowo nie spełni żadnego z powyższych warunków, to jego tokenem będzie zwykły `--unk--`. Warunki będą oceniane w tej samej kolejności, co tutaj wymienione. Więc jeśli słowo zawiera znak interpunkcyjny, ale nie zawiera cyfr, to będzie podlegało drugiemu warunkowi. Aby osiągnąć takie zachowanie, niektóre wyrażenia if/elif mogą być używane wraz z wczesnymi zwrotami. \n",
    "\n",
    "Funkcja ta jest zaimplementowana poniżej. Zauważ, że funkcja `any()` jest często używana. Zwraca `True` jeśli przynajmniej jeden z przypadków, który ocenia, jest `True`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def assign_unk(word):\n",
    "    \"\"\"\n",
    "    Przypisuje tokeny nieznanym słowom\n",
    "    \"\"\"\n",
    "    \n",
    "    # Znaki interpunkcyjne\n",
    "    # Spróbuj wypisać je w oddzielnej komórce\n",
    "    punct = set(string.punctuation)\n",
    "    \n",
    "    # przyrostki\n",
    "    noun_suffix = [\"action\", \"age\", \"ance\", \"cy\", \"dom\", \"ee\", \"ence\", \"er\", \"hood\", \"ion\", \"ism\", \"ist\", \"ity\", \"ling\", \"ment\", \"ness\", \"or\", \"ry\", \"scape\", \"ship\", \"ty\"]\n",
    "    verb_suffix = [\"ate\", \"ify\", \"ise\", \"ize\"]\n",
    "    adj_suffix = [\"able\", \"ese\", \"ful\", \"i\", \"ian\", \"ible\", \"ic\", \"ish\", \"ive\", \"less\", \"ly\", \"ous\"]\n",
    "    adv_suffix = [\"ward\", \"wards\", \"wise\"]\n",
    "\n",
    "    # Pętla po wszystkich znakach w słowie, sprawdzamy czy któryś ze znaków nie jest cyfrą\n",
    "    if any(char.isdigit() for char in word):\n",
    "        return \"--unk_digit--\"\n",
    "\n",
    "    # Pętla po wszystkich znakach w słowie, sprawdzamy czy któryś ze znaków nie jest znakiem interpunkcyjnym\n",
    "    elif any(char in punct for char in word):\n",
    "        return \"--unk_punct--\"\n",
    "\n",
    "    # Pętla po wszystkich znakach w słowie, sprawdzamy czy któryś ze znaków nie jest wielką literą\n",
    "    elif any(char.isupper() for char in word):\n",
    "        return \"--unk_upper--\"\n",
    "\n",
    "    # Sprawdzamy czy słowo nie kończy się rzeczownikowym przyrostkiem\n",
    "    elif any(word.endswith(suffix) for suffix in noun_suffix):\n",
    "        return \"--unk_noun--\"\n",
    "\n",
    "    # Sprawdzamy czy słowo nie kończy się czasownikowym przyrostkiem\n",
    "    elif any(word.endswith(suffix) for suffix in verb_suffix):\n",
    "        return \"--unk_verb--\"\n",
    "\n",
    "    # Sprawdzamy czy słowo nie kończy się przymiotnikowym przyrostkiem\n",
    "    elif any(word.endswith(suffix) for suffix in adj_suffix):\n",
    "        return \"--unk_adj--\"\n",
    "\n",
    "    # Sprawdzamy czy słowo nie kończy się przysłówkowym przyrostkiem\n",
    "    elif any(word.endswith(suffix) for suffix in adv_suffix):\n",
    "        return \"--unk_adv--\"\n",
    "    \n",
    "    # Jeżeli żaden z powyższych warunków nie jest spełniony to przypisujemy zwykły UNK\n",
    "    return \"--unk--\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'-', ';', '!', '{', '?', '\"', '$', '~', '@', '&', '<', '*', ':', '#', '%', '^', '}', '`', ',', \"'\", '\\\\', '.', '(', '[', '>', '_', ']', ')', '/', '+', '|', '='}\n"
     ]
    }
   ],
   "source": [
    "punct = set(string.punctuation)\n",
    "print(punct)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tworzony przez nas model oznaczający części mowy zawsze natrafi na słowa, których nie będzie w używanym przez nas słowniku. Poprzez powiększenie zbioru danych, włączając te `nieznane tokeny słów` pomagasz modelowu mieć lepsze wyobrażenie o odpowiednim tagu dla tych słów."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Otrzymywanie poprawnego tagu dla słowa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pozostaje tylko zaimplementować funkcję, która uzyska odpowiedni tag dla danego słowa, biorąc pod uwagę nieznane słowa. Ponieważ zbiór danych dostarcza każde słowo i tag w tym samym wierszu, a to, czy dane słowo jest znane, zależy od użytego słownika, te dwa elementy powinny być argumentami dla tej funkcji.\n",
    "\n",
    "Funkcja ta powinna sprawdzić, czy wiersz jest pusty, a jeśli tak, to powinna zwrócić odpowiednio słowo i znacznik typu placeholder, `--n--` i `--s--`. \n",
    "\n",
    "Jeśli nie, to powinna przetworzyć wiersz, by zwrócić poprawną parę słów i znaczników, rozważając, czy słowo nie jest nieznane, w tym wypadku powinna być użyta funkcja `assign_unk()`.\n",
    "\n",
    "Funkcja jest implementowana poniżej. Zauważ, że metoda `split()` może być użyta bez określania znaku rozdzielającego, w którym to przypadku będzie domyślna dla każdej spacji."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_word_tag(line, vocab):\n",
    "    # jeżeli wiersz jest pusty to zwracamy placeholdery\n",
    "    if not line.split():\n",
    "        word = \"--n--\"\n",
    "        tag = \"--s--\"\n",
    "    else:\n",
    "        # rozdzielamy wiersz, aby oddzielić słowo od tagu\n",
    "        word, tag = line.split()\n",
    "        # sprawdzamy czy słowo jest w słowniku\n",
    "        if word not in vocab: \n",
    "            # przypisujemy tag dla nieznanego słowa\n",
    "            word = assign_unk(word)\n",
    "    return word, tag"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Teraz możesz spróbować tej funkcji z kilkoma przykładami, aby sprawdzić, czy działa ona zgodnie z założeniami:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('--n--', '--s--')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_word_tag('\\n', vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ponieważ ten wiersz zawiera tylko znak nowej linii, funkcja zwraca słowo i tag zastępczy (placeholder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('In', 'IN')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_word_tag('In\\tIN\\n', vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ten wiersz jest poprawny, a funkcja wykonuje się prawidłowo i zwraca poprawną parę (słowo, tag)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('--unk--', 'NN')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_word_tag('tardigrade\\tNN\\n', vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ten wiersz zawiera rzeczownik, który nie jest obecny w słowniku. \n",
    "\n",
    "Funkcja `assign_unk` nie wykrywa, że jest rzeczownikiem, więc zwraca `nieznany token`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('--unk_verb--', 'VB')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_word_tag('scrutinize\\tVB\\n', vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ten wiersz zawiera czasownik, który nie jest obecny w słownictwie. \n",
    "\n",
    "W tym przypadku `assign_unk` jest w stanie wykryć, że jest to czasownik, więc zwraca `nieznany token czasownika`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Gratuluję ukończenia tego notebooka!** Teraz powinieneś być bardziej zaznajomiony z pracą z danymi tekstowymi i lepiej rozumieć jak działa podstawowy model oznaczający części mowy.\n",
    "\n",
    "**Kontynuuj dobrą robotę!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0b4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
